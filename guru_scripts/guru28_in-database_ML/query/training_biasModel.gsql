CREATE QUERY training_biasModel(DOUBLE alpha = 0.001, DOUBLE lambda = 0.02, INT Iter=10, INT num_latent_factors = 10) FOR GRAPH Recommender {
	ListAccum<DOUBLE> @tmp;
	ArrayAccum<SumAccum<double>> @theta[10];  #modify list length according to num_latent_factors
	ArrayAccum<SumAccum<double>> @x[10];
	ArrayAccum<SumAccum<double>> @Gradient[10];
	SumAccum<double> @theta_bias;
	SumAccum<double> @x_bias;
	SumAccum<double> @Gradient_bias;
	SumAccum<DOUBLE> @@RMSE_training;
	SumAccum<DOUBLE> @@RMSE_validation;
	#DOUBLE cnt_training = 70737;  #ml-20m:  14189115
  #DOUBLE cnt_validation = 29274;  #ml-20m: 5811148
	
	DOUBLE cnt_training = 66274;  #ml-100k:  100000-33726
  DOUBLE cnt_validation = 33726;  #ml-100k: 33726

	#DOUBLE cnt_training = 14421774;#14360980;  #14189115;# 14421774;
  #DOUBLE cnt_validation = 5578489;#5639283;  #5811148;# 5578489;



	#DOUBLE lambda = 10;
	## pass x and theta to local accum


	MOVIEs = {MOVIE.*};

#	M1 = SELECT s FROM MOVIEs:s
#	     WHERE s.movie_id == "1";

	MOVIEs = SELECT s FROM MOVIEs:s
	         ACCUM
	           s.@x_bias = s.x.get(num_latent_factors),
	           FOREACH i IN RANGE[0,num_latent_factors-1] DO
	             s.@x[i] += s.x.get(i)
	           END;

	USERs = {USER.*};
	USERs = SELECT s FROM USERs:s
	        ACCUM
	           s.@theta_bias = s.theta.get(num_latent_factors),
	           FOREACH i IN RANGE[0,num_latent_factors-1] DO
	             s.@theta[i] += s.theta.get(i)
	           END;



	## compute gradient
	WHILE TRUE LIMIT Iter DO
	@@RMSE_training = 0;
	@@RMSE_validation = 0;
	USERs = SELECT s FROM USERs:s
	        ACCUM
	          s.@Gradient_bias = 0,
	          s.@Gradient.reallocate(num_latent_factors);

  MOVIEs = SELECT s FROM MOVIEs:s
	        ACCUM
	          s.@Gradient_bias = 0,
	          s.@Gradient.reallocate(num_latent_factors);

	USERs = SELECT s FROM USERs:s -(rate:e)-> MOVIE:t
	        ACCUM
	          DOUBLE delta = dotProduct_ArrayAccum_ArrayAccum(s.@theta,t.@x)+s.@theta_bias+t.@x_bias,
	          delta = delta-e.rating,
	          IF e.label THEN
	            @@RMSE_training += delta*delta,
	            s.@Gradient += product_ArrayAccum_const(t.@x,delta),
	            s.@Gradient += product_ArrayAccum_const(s.@theta,lambda),
	            s.@Gradient_bias += s.@theta_bias*lambda*0.1,
	            s.@Gradient_bias += delta,
	            t.@Gradient += product_ArrayAccum_const(s.@theta,delta),
	            t.@Gradient_bias += t.@theta_bias*lambda*0.1,
	            t.@Gradient += product_ArrayAccum_const(t.@x,lambda),
	            t.@Gradient_bias += delta
	          ELSE
	            @@RMSE_validation += delta*delta
	          END
	        POST-ACCUM
#	          s.@Gradient += product_ArrayAccum_const(s.@theta,lambda),
	          s.@theta += product_ArrayAccum_const(s.@Gradient,-alpha),
#	          s.@Gradient_bias += s.@theta_bias*lambda,
	          s.@theta_bias += (-alpha*s.@Gradient_bias),
#	          t.@Gradient_bias += t.@theta_bias*lambda,
	          t.@theta_bias += (-alpha*t.@Gradient_bias),
#	          t.@Gradient += product_ArrayAccum_const(t.@x,lambda),
	          t.@x += product_ArrayAccum_const(t.@Gradient,-alpha);


	PRINT sqrt(@@RMSE_training/cnt_training);
	PRINT sqrt(@@RMSE_validation/cnt_validation);
#	PRINT M1;
	END;


	## pass local accum to x and theta
	MOVIEs = SELECT s FROM MOVIEs:s
	         POST-ACCUM
	           s.@tmp.clear(),
	           FOREACH i IN RANGE[0,num_latent_factors-1] DO
#	             s.x.update(i,s.@x[i])
	             s.@tmp += s.@x[i]
	           END,
	           s.@tmp += s.@x_bias,
	           s.x = s.@tmp;


	USERs = SELECT s FROM USERs:s
	        POST-ACCUM
	           s.@tmp.clear(),
	           FOREACH i IN RANGE[0,num_latent_factors-1] DO
#	             s.x.update(i,s.@x[i])
	             s.@tmp += s.@theta[i]
	           END,
	           s.@tmp += s.@theta_bias,
	           s.theta = s.@tmp;

#  PRINT M1;
}

