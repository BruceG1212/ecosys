This document details how to reproduce the deep-link traversal on a 1.48-billion-edge twitter graph.

Data Sets
===========
- twitter edge file:  http://service.tigergraph.com/download/benchmark/dataset/twitter/twitter_rv.tar.gz
After you download it to a data folder, untar it

tar xvf twitter_rv.tar.gz

Hardware
===========
Amazon EC2 machine C3.8xlarge. 

32vCPUs, 60GiB memory, attached a 512G  EBS-optimized Provisioned IOPS SSD (IO1), IOPS we set is 25.6k. Raw data and neo4j are put on this SSD. 

Note: you can use a General Purpose SSD and other EC2 machine, as far as it has 20GiB memory and 80GiB SSD.

Software
============
Download TigerGraph Developer Edition from here https://www.tigergraph.com/download/ and install it.

GSQL script
=============
- setup.gsql
open this file with an editor, and change the twitter file location to your data folder.

- khop.gsql
the khop deep link traversal query. See 41:40 demo here https://www.youtube.com/watch?v=EslAkGAEbFs&t=2s

Setup Schema and Load
=========================
- switch to tigergraph user

   su tigergraph/tigergraph 

- start all service

   gadmin start all

- setup schema
 
  Enter gsql shell by "gsql" without quotes

  GSQL>@setup.gsql

- load data from command line

   nohup gsql -g twitter 'run loading job load_twitter_edge'

Run the query
===============
- open gsql shell by "gsql" without quotes. 
- install khop query by
GSQL> @khop.gsql

It takes about 1 minute. Then, try the k-hop query. Some sample input user is in the khop.gsql comments part.

Thank you! If you like deep-link analytics, join the GSQL developer community at 

https://groups.google.com/a/opengsql.org/forum/?hl=en#!forum/gsql-users

